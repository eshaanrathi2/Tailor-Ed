{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Remove comments from pip install instructions if in colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDhNllB-z0aK",
        "outputId": "a20e5011-cd8e-45a9-b829-5a31f2c2be24"
      },
      "outputs": [],
      "source": [
        "# !pip install jq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AtFTY-rD24NF"
      },
      "outputs": [],
      "source": [
        "# !pip install langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZDKLBKn6H63",
        "outputId": "4473d6cf-6cdb-4627-fc30-177a3f9d4c40"
      },
      "outputs": [],
      "source": [
        "# %pip install --upgrade --quiet  langchain langchain-community langchainhub langchain-openai chromadb bs4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "zdwWIYb727JN"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import JSONLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "h18KvlZD3K_D"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "from pprint import pprint\n",
        "\n",
        "\n",
        "# file_path='/content/test.json'\n",
        "file_path='/Users/eshaan/Desktop/projects/Tailor-Ed/data/test.json'\n",
        "data = json.loads(Path(file_path).read_text())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1PEqq__3NVl",
        "outputId": "08dde5f1-5dce-44e5-d210-5e2650978368"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n"
          ]
        }
      ],
      "source": [
        "print(len(data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "ENvSCOFx3-11"
      },
      "outputs": [],
      "source": [
        "loader = JSONLoader(\n",
        "    file_path=file_path,\n",
        "    jq_schema='.docs[].content',\n",
        "    text_content=False)\n",
        "\n",
        "data = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDJ_wEU337gv",
        "outputId": "42528b00-c39d-4372-bade-8396f24fc478"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Document(page_content='MATH 1A SECTION 1 CRN 31484 WINTER 2019\\n\\nInstructor: Dr. Zack Judson Office: E36B\\n\\nOffice Hours: MWF 9:30-10:20 TTh 12:30-1:20\\n\\nEmail: judsonzack@deanza.edu (Note: I will not answer Math questions over email)\\nPrerequisite: Math 43 or an equivalent course\\n\\nRequired Materials\\n\\n1) “Calculus Early Transcendentals, 8\" Edition” by James Stewart\\n\\n2) Calculator: TI83/84 graphing calculator or similar\\nTI89 or any calculator with a CAS will not be allowed.\\nCalculators will be required on about half of the tests and quizzes.\\n\\nGrade\\nYour grade will be computed using the following grade distribution.\\n5% Labs 10% Quizzes\\n9% Discussion 40% Midterms (4)\\n10% Homework 30% Final\\n\\nExams\\n\\nThree exams will be given with no make-ups. The lowest exam will count for 10% while the\\nother two will count for 15% each. If an exam is missed under extreme circumstances and for a\\nvery valid reason, an equivalent of the final score will replace the missing exam score. If such\\nextreme circumstances occur it is the students responsibility to inform me immediately and\\n\\nprovide documentation of the circumstances.\\n\\nQuizzes\\n\\nThere will be two types of quizzes given throughout the quarter. The first quiz will be a\\nprerequisite quiz which covers many of the things that you are supposed to know in order to be in\\nthis course and which will be used throughout this quarter. You will be given the entire class time\\nfor the prerequisite quiz. Approximately weekly, following the attached schedule we will have\\ncommunity quizzes. These quizzes will be 15 to 20 minutes long, but after the first ten minutes\\nyou may work with anyone and everyone in the class to complete your quiz. Each community\\nquiz will be scored out of 20 points. The lowest quiz score will be dropped. There will be no\\n\\nmake-ups for missed quizzes.\\nLabs\\n\\nA half dozen times throughout the quarter we will have lab assignments. The intentions behind\\nlab assignments is to encourage students to think more deeply about the material. These labs will\\nbe worked on in groups of three or four. There will be some initial time allotted to these lab\\nassignments during class, but you will need to work on them outside of class to complete them.\\nAlthough every student must turn in a copy of the lab, you will be graded as a group on the\\nassignment. For further information regarding the lab assignments please read the Lab Grading\\nPolicies later in this document. No late lab assignments will be accepted. Your lowest lab score\\n\\nwill be dropped.\\n\\x0cHomework\\n\\nHomework will be due approximately weekly. The due dates are already listed on the schedule.\\nYou need to turn in your assignment as soon as you walk into class, even if you are late to class.\\nThe problems must be completed in the order they are assigned, skipping a line between\\nproblems. You may use up to two columns on your page. If you choose to use two columns you\\nmust complete the column on the left before moving on to the column on the right. All pages of\\nthe homework must be stapled together. Four points of your homework grade are allotted to\\nformatting. On the first assignment you will be penalized 1 point per formatting error. On the\\nsecond assignment you will be penalized 2 points per formatting error. After the second\\nassignment any formatting error will forfeit all 4 points that are assigned for formatting. Each\\nhomework will consist of 20 problems. Four of these problems will be graded for content. These\\nwill be graded out of 5 points each. You will not know which 4 problems will be graded. For the\\nremaining 16 problems you will be awarded one point each provided that I believe you attempted\\nthe problem. In this way each assignment is worth 40 points. Some homeworks will list\\nAdditional Problems. These are required problems that are part of the assignments 20 problems.\\nEach assignment will also list Honors Problems. If you are not taking the honors section of this\\ncourse you are not required to do the Honors Problems. No late work will be accepted. Your\\nlowest homework score will be dropped.\\n\\nDiscussion\\n\\nThe only way to learn math is to practice math. For this reason, we will be having discussions on\\nan approximately weekly basis. In discussion we will work in groups on additional problems.\\nYour work will be graded on participation and effort.\\n\\nFinal Exam\\n\\nA two-hour comprehensive final exam will be given on Monday, March 25 from 7 to 9 am.\\n\\nAccomodations\\n\\nHonors\\n\\nThose of you who need additional accommodations, due to disability, campus-related\\nactivities, or some other reason, please meet with me during the first two weeks of class\\nto discuss your options.\\n\\nIf you are taking the honors section of this course you will be required to do the honors problems\\non the homework assignments. These problems will represent half of your homework grade. In\\nlieu of your discussion grade you will also complete an honors project. The honors project will be\\na somewhat shorter version of a lab assignment that you will complete individually.\\n\\nGrading Scale\\n\\nDue to the complexity of the material the grading scale we will use is as follows\\n\\nA :90—-100 B+: 80—84 C+: 67-69 D: 50—59 F: 0-49\\nA—: 85-89 B : 75-79 C  : 60-66\\nB—: 70-74\\n\\x0cTentative Schedule\\nMath 1A Winter Quarter 2019\\n\\np Monday | Tuesday | Wednesday Thursday\\n\\nIntroductions Review of Families of Building\\nJanuary Ch. 2.1 Functions Functions Functions\\n7 8 Ch 1 9 Ch. 1 10 Chl\\n\\nfrmwy Limit Laws Discussion 1 Lab 1 (part 1)\\nJanuary Ch. 2.3\\n\\n15 16 17\\n\\nMartin Luther Continuity Continuity Limits at 0o\\nJanuary King Jr. Day Ch. 2.5 Ch. 2.5 Ch. 2.6\\n\\n21 22 23 24\\n\\nJanuary/ Derivatives Derivatives Basic Lab 2\\nFebruary Quiz 2 Hw 3 due | Ch. 2.8 Derivatives\\n28 Ch. 2.7 29 30. =Ch.3.1 31\\n\\nProduct and Trigonometric Discussion 3 The Chain Rule\\nFebruary Quotient Rules Derivatives Ch. 3.4\\n\\n4 Ch. 3.2 5 Ch. 3.3 6 7  Hw5 due\\n\\n(Ch. 3.5) Implicit | Logarithmic Discussion 5 Lab 3\\nFebruary Differentiation Differentiation Hw 6 due Quiz 4\\n\\n11 Lab2due |12 Ch.3.6 13 14\\n\\nPresident’s Applications Related Rates Related Rates\\nFebruary Weekend Ch. 3.7 Ch. 3.9 Ch. 3.9\\n\\n18 19 Hw7due |20 Quiz5 21 Lab3 due\\n\\nFebruary/ (Ch. 3.10) Linear Relative Extrema | Midterm 2\\nMarch Approximation Ch. 4.1 Hw 9 due\\n25 Hw8 due 27 28\\n\\nDiscussion 7 Derivatives and | Derivatives and | Lab 5\\nMarch Graphs Ch. 4.3 | Graphs Quiz 7\\n4 5 Lab 4due 6 Ch. 4.3 7  Hw10due\\nDiscussion 8 Optimization Optimization Newton’s\\nMarch Ch. 4.7 Quiz 8 Method\\n11 12 13. Hwilldue/14 Ch4.8\\nAnti-Derivatives | Discussion 9 Midterm 4 Discussion 10\\nMarch Ch. 4.9\\n18 Hwl2due | 19 20 21\\nDecember 7:00-9:00am\\n25 27 28\\n\\nImportant Dates: January 19: Last day to add aclass\\nJanuary 20: Last day to drop with no grade on record.\\nFebruary 1: Last day to request Pass/No Pass grade.\\nMarch 1: Last day to drop with a \"W\".\\n\\n     \\n       \\n   \\n      \\n\\n \\n\\nPrerequisite\\nQuiz\\n\\n11 HwtI due\\nLab 1 (part 2)\\nQuiz |\\n\\n18 Hw2due\\nDiscussion 2\\nLab 1 due\\n\\n25\\n\\nMidterm 1\\n\\nHw 4 due\\n\\nl\\n\\nDiscussion 4\\nQuiz 3\\n\\n8\\n\\nPresident’s\\nWeekend\\n\\n15\\n\\nDiscussion 6\\n\\n22\\n\\nMean Value\\nTheorem\\n\\nl Ch. 4.2\\nL’Hospital’s\\nRule\\n\\n8 Ch. 4.4\\n\\nQuiz 9\\nHw 13 due\\n22 Lab 6due\\n\\n \\n\\x0cLab Grading Policies\\n\\nNobody makes it into a Calculus class without being exceptionally bright. For this reason, you may at\\nsome time in the past, have decided that it is easier to work alone than to work with others. This is\\nunfortunate for two reasons:\\n\\n1) The further you go in Math (or any other discipline) the more difficult the material\\nbecomes. If you go far enough, no matter how smart you are, you will reach a point that you\\ncannot proceed without help.\\n\\n2) Presumably the end result of your education will be to obtain a job that you enjoy and_ that\\nwill maintain you in a style in which you enjoy. Almost certainly this job will require you to work\\nwith others.\\n\\nThe labs we will cover in this class serve two purposes, they allow us to dig deeper into the fertile soil of\\nthe Calculus and they provide us the opportunity to develop our co-operative skills. Most of you, at some\\npoint after you transfer will take a class where a single group project might be worth as much as one of\\nyour midterms. It can be difficult to rely on others for such a large part of your grade. To ease you into\\nthese dynamics, your labs represent a relatively small part of your grade, each lab accounting for about\\n1%. Part of your grade for each of these labs will depend on the other members of your group.\\n\\nGeneral Grading: Each lab member is required to turn in their own lab report. Failure to turn in a lab\\nreport will result in a 0 for that lab member. There will be no late labs accepted. Each lab will be graded\\nout of 100 points. Except where indicated on an individual lab, I will randomly select different lab reports\\nto assess for each section of the lab. Every member of the lab group will receive the same score for a\\nparticular section as the one member whose report I assessed for that section. As a result all labs will be\\nreturned to the group rather than the individual members. It is in your best interest to meet with your\\ngroup outside of class time to make sure that everyone understands and agrees upon conclusions.\\n\\nGroup Size: Groups must consist of three or four people. Groups must be declared on the day a lab is\\nintroduced. After the first lab you will have the opportunity to choose your own groups provided that\\neveryone who is present on time on a lab day has the opportunity to join a group with at least 3 members.\\nIf this is not the case, I reserve the right to reform groups as needed. You may change lab groups with\\neach lab, but you are not required to do so. All lab days are already on your calendar. If you are not there\\non a lab day, you may still do the lab as a group of 1, but you will be subject to a 20 point penalty. You\\nmay, of course, make arrangements with other members of the class to declare yourself as part of their\\ngroup on the day groups are declared.\\n\\nIncompletes: To avoid groups being penalized for a member who does not complete certain sections you\\nwill need to indicate whenever your lab is incomplete. You MUST write Incomplete at the top of the front\\npage of your lab and indicate which sections you did not do. Your lab will only be graded out of the\\nsections you completed. Failure to do this may result in a score of 0 for the individual who has an\\nincomplete lab.\\n\\x0cStudent Learning Outcome(s):\\n\\n* Analyze and synthesize the concepts of limits, continuity, and differentiation from a graphical,\\nnumerical, analytical and verbal approach, using correct notation and mathematical precision.\\n*Evaluate the behavior of graphs in the context of limits, continuity and differentiability.\\n*Recognize, diagnose, and decide on the appropriate method for solving applied real world\\nproblems in optimization, related rates and numerical approximation.\\n\\x0c', metadata={'source': '/Users/eshaan/Desktop/projects/Tailor-Ed/data/test.json', 'seq_num': 1}),\n",
            " Document(page_content='Instructor: Amanda Lien\\nOffice: S75b\\nOffice Hours: MTWTh 10:30-11:20AM\\n\\nContact: lienamanda@fhda.edu\\n\\nMATH 1A: Calculus I ¢ Sec 05 ¢ Winter 2019\\nRoom E36 * MTWTHE 9:30-10:20AM\\n\\nCOURSE DESCRIPTION\\nFundamentals of differential calculus. (5 units)\\nPREREQUISITE\\n\\nMATH 43 (with a grade of C or better), or appropriate score on Calculus Placement Test within the past\\ncalendar year. Advisory: EWRT 211 and READ 211 (or LART 211), or ESL 272 and 273.\\n\\nREQUIRED MATERIALS\\n\\n- WebAssign access code (see HOMEWORK for more information)\\n- One three-ring binder for notes, exams, quizzes, and other handouts\\n- Graphing calculator (TI-83/TI-83 Plus/TI-84/TI-84 Plus)\\n\\n- Pencils, erasers, colored pens, paper, ruler/straight-edge\\n\\n- Lecture notes printed for each class meeting\\n\\nTEXTBOOK\\n- Calculus Early Transcendentals by James Stewart, 8\" edition ISBN: 978-1337494748\\n\\nIMPORTANT DATES*\\n\\nFriday, January 11\\nFriday, January 18\\nSaturday, January 15\\nSunday, January 20\\nMonday, January 21 “Midterm dates and\\nFriday, January 25 coverage are subject\\n\\nFriday, February 1 Quiz #3 to change. Final\\nLast day to request pass/no pass grade\\n\\nexam date/time is\\n\\nFriday, February 8 fixed. The instructor\\nThursday, February 14 will communicate\\nFriday, February 15 any changes in class\\nMonday, February 18 and via email.\\nFriday, February 22\\n\\nFriday, March 1 Quiz #6\\nLast day to drop with a “W”\\n\\nFriday, March 8\\nFriday, March 15\\nFriday, March 22\\nTuesday, March 26\\n\\n \\n\\x0cCOMMUNICATION\\n\\nI will be using email and Canvas to communicate with you outside of classroom time. Canvas is accessible to\\nall students enrolled in the course (https://deanza.instructure.com/) using the MyPortal login credentials. You\\nneed check your email on a regular basis as I will send out homework, exam dates, and study reminders. All\\nclass handouts, skeleton lecture notes, quiz/midterm solutions, etc. will be uploaded onto Canvas. If you miss\\nclass, you will need to print out the lecture notes and ask a classmate to share his/her completed lecture notes\\nwith you. If you need to contact me, please email me directly. Do not contact me via WebAssign, as I may not\\nsee it.\\n\\nMAKE-UPS POLICY\\n\\nYou MUST take the exams on the dates listed. There are absolutely no make-up quizzes, homework, or exams.\\nThe final exam date and time have been determined and mandated by the college. No early/late final exam may\\nbe scheduled. If you know that you are unable to take the final at the date and time above, you must drop the\\nclass now.\\n\\nHOMEWORK\\nWebAssign:\\n\\n- https://webassign.com/ (assigned after the completion of each section)\\n\\n- You must have an access code and do the assignments on WebAssign to be successful in this course.\\nTherefore it is mandatory that you be an active user of WebAssign. Students who are registered in\\nMath 1A but do not have an account will be dropped. If you need some time to get financial aid or\\nto save Up Money, you can use the trial period for the first week.\\n\\n- Enter in our class key:\\n\\n- You will be able to access the assignments after each section has been presented in class. They are due\\n5 days after the assigned date at 11PM. For example, if I assign WebAssign homework on a Monday at\\n10:30AM, it must be completed by that Saturday at 11PM. Please do not procrastinate!\\n\\nCollaboration on the homework is encouraged, but each student must write his/her own solutions and not copy\\nthem from anyone else. If you have questions about problems from WebAssign, you may email me or see me\\nin office hours. No late assignments accepted!\\n\\nQUIZZES\\n\\nAn in-class quiz will be given once per week on Friday, except for the weeks where a midterm/final exam is\\nscheduled. The quiz will include topics that were covered during that particular week and/or the previous week.\\nYou are permitted to use any and all of your lecture notes to help you with the quiz. There will be a total of 7\\nquizzes this quarter.\\n\\nATTENDANCE\\n\\nIt is essential that you participate and regularly ask questions in order to succeed in this course and your future\\nmath courses. Therefore, attendance is required and students are expected to attend all sessions of each class.\\nAttendance may be taken at any point during the class (beginning, middle, or end). If you use your\\nphone/tablet/laptop or any unrelated material, I may ask you to leave and that day will count as an absence.\\n\\nInstructors may drop students from class if they fail to attend the first class meeting, or when accumulated\\nunexcused hours of absence exceed ten percent of the total number of hours the class meets during the quarter.\\nI will drop students who do not attend the first class meeting. You should NOT rely on your instructor to\\ndrop you from your course. If you decide to stop attending class, it is your responsibility to drop. Failure to do\\nso will result in a grade of F.\\n\\x0cCLASSROOM ETTIQUETTE\\n\\n- Keep your cell phones on silent and hidden.\\n\\n- To promote a safe and positive learning environment, you are to be respectful to me and to your\\nclassmates. Please do not talk during lecture. If you have a question, raise your hand.\\n\\n- Your full attention and participation is expected.\\n\\n- You are required to come to class prepared WITH lecture notes printed out.\\n\\nGRADING\\n\\n- Attendance is mandatory as part of your participation grade. You must also be present to completely fill\\nin your binder for the binder check at the end of the quarter.\\n\\n- Please see the FAQ at the end of the syllabus for information about the binder check.\\n\\n- There will be three in-class midterms and a final. Please bring in a valid photo ID on exam days.\\n\\n- If your final exam score is higher than any of your midterm scores, the final exam score (excluding any\\nextra credit points) will be used to replace the lowest midterm score. If the lowest midterm score is a\\nresult of cheating, it will not be considered for the replacement.\\n\\n- Your two (2) lowest WebAssign homework score will be dropped. However, I still encourage you to do\\nall assignments in order to get the most out of this course. Remember that practice is key!\\n\\n- Your lowest quiz score will be dropped.\\n\\n- The grades for the exams will be changed only if there is a clear error on my part, such as adding up\\nmarks incorrectly. Problems must be brought to my attention immediately after exams are returned.\\n\\n- Changing your work (adding to and/or erasing any of your work) after the exam has been graded is\\nconsidered to be academic dishonesty and you may eam a 0 on the exam.\\n\\n- An incomplete grade (I) is rarely assigned. It will only be assigned in extreme situations (i.e.\\nunforeseeable emergency and justifiable reason at the end of the term that prevent you from completing\\nthe course). You must be in good standing with near-perfect attendance and an overall grade of a 70%\\n(C) or greater in order to request for an incomplete grade.\\n\\nBreakdown of grades:\\nHomework\\n63-879% «BO\\n\\n80-82.9% «|B\\n63-679% «(DS\\n60-62.9% «(| D-\\n\\n \\n\\nFinal grades are non-negotiable. You should monitor your scores in the gradebook regularly throughout the\\nquarter. If there are any discrepancies, they should be brought to my attention as soon as possible.\\n\\x0cTUTORING\\n\\nTutoring is available for all students in the Tutorial Center, S-43. Tutoring is provided at no charge by qualified,\\ntrained tutors. Tutors can give students feedback on their course work, help them understand assignments and\\nprovide students strategies for improving their learning skills.\\n\\nFor more information, visit http://www.deanza.edu/studentsuccess/mstrc/\\nACADEMIC DISHONESTY\\n\\nBy enrolling in this class you agree to uphold the standards of academic integrity as outlined in the current De\\nAnza college catalogue. Dishonesty includes but is not limited to signing in someone other than yourself on the\\nattendance sheet, in-class cheating, out-of-class cheating, plagiarism, knowingly assisting another student in\\ncheating or plagiarism, or knowingly furnishing false information to college staff, faculty, administrators or\\nother officials. If you are observed cheating, you may receive an F on the assignment/exam and be\\ndismissed from the course. Furthermore, the incident will be reported to the Dean of Student\\nDevelopment for review and a note will be made in your school records. Please do not give me any reason\\nto suspect cheating.\\n\\nCODE OF STUDENT CONDUCT\\n\\nThe college has an obligation to specify those standards of behavior essential to its educational mission and\\ncampus life. The students who are in violation of the Code of Student Conduct are subject to disciplinary\\nsanctions which apply at all times on campus as well as to any off-campus functions sponsored or supervised\\nby the college.\\n\\nACCESSIBILITY ACCOMODATIONS\\n\\nIf you have a documented disability and wish to discuss academic accommodations, or if you would need\\nassistance in the event of an emergency evacuation, please inform me as soon as possible.\\n\\nEMERGENCY INFORMATION\\n\\nCheck out the Emergency website for information on what to do in an emergency (earthquake, electrical\\noutage, fire, extreme heat, severe storm, hazardous materials, terrorist attack) here:\\nhttps://www.deanza.edu/emergency/. Be familiar with these procedures. Information on this page is updated\\nas required.\\n\\nLAST NOTE\\n\\nPlease remember that you are responsible for your education. This means that if you are having trouble\\nunderstanding a concept presented in class, I encourage you to ask questions during class or in office hours. Do\\nnot wait until the end of the quarter to realize that you need help. Math and Statistics are hierarchical subjects\\n— they continue to build up on knowledge from previous material. If you miss a lecture, ask a friend to share\\nhis/her lecture notes with you.\\n\\nFrequently Asked Questions\\n\\nBefore emailing me, please refer to this sheet.\\n\\nQUESTION: What is expected of me in each lecture?\\n\\nANSWER: You are expected to come prepared with your graphing calculator and pencils/pens to take notes\\nalong with your 3-ring binder for this class. You MUST print out and bring “skeleton” lecture notes in which\\nyou will fill in. If there are problems for you to try on your own, you are expected to do the work.\\n\\x0cAt the beginning of lecture, if you have questions about the homework from the night before, you may ask\\nthose question. Doing so will not only help you, but other people in class.\\n\\nMake sure to sign in on the attendance sheet for each lecture. Do NOT sign in for anyone else.\\n\\nQUESTION: I am sick and cannot make it to lecture today. What should I do?\\n\\nANSWER: You need to email me with your situation so that you are excused. Lecture notes are posted on\\nCanvas. You will need to download the notes, print them out, and ask a fellow classmate to share their filled-\\nin notes with you. I will not scan my written notes onto Canvas. If a quiz was given, I will drop your lowest\\nquiz score.\\n\\nQUESTION: I am having trouble with a homework problem. How should I ask you for help?\\n\\nANSWER: You can come into my office hours to ask for help. If you are unable to visit me at that time, then\\nyou can send me a specific email about the question. Your email asking me for help must have the three main\\nparts:\\n\\n1. Tell me the exact question number and what section it is from.\\n2. Copy and paste the problem into the email.\\n3. Show me your attempt at the problem. In other words, do not simply email me the phrase, “I don’t get it.”\\n\\nExample:\\nSubject: Math 1A Homework Help\\n\\nHi Ms. Lien:\\n\\nIT am stuck on problem on WebAssign section . The problem is... (copy\\nand paste the homework question here). This is what I tried to do... (show me your\\nattempt - you can type out what you tried or you can take a picture of your work\\n\\nand attach it in the email).\\n\\nThanks,\\n(your first AND last name)\\n\\nNote: If I am not able to identify who you are based on your email address or name at the end of the email, I\\nwill not respond. Furthermore, if you do not follow this format of the three parts required when asking for\\nhelp on homework, I will not respond.\\n\\nQUESTION: I was not able to do the WebAssign homework because ___. Will you grant me an extension?\\nANSWER: No. In this course, there are no make-up assignments. However, I understand that unforeseen\\nevents may come up during the quarter that may prevent you from completing an assignment on time. This is\\nwhy I will drop your two (2) lowest WebAssign homework assignment at the end of the quarter.\\n\\nQUESTION: I missed a midterm. Can I make it up?\\n\\nANSWER: Unless you had a prior arrangement with me, you may not make up a midterm. If you know that\\nyou cannot take a midterm on the assigned date, you must bring this to my attention at the beginning of the\\nquarter for an alternative.\\n\\nQUESTION: What is the binder check?\\nANSWER: On the last lecture of the quarter (Friday, March 22), I will check your binder for lecture notes,\\n\\x0cquizzes, midterms, corrections, and any other handouts given in class. All lecture notes must be filled in,\\nwhich is why it is important that you attend all lecture meetings. However, if you must miss class, you can\\nalways print out the notes (from Canvas) and ask a classmate to share their completed notes with you. All\\npages MUST be hole-punched and properly placed in order in a 3-ring binder.\\n\\nWhat should be in your binder by the last lecture:\\n\\n1. All lecture notes, completed and filled in with YOUR handwriting\\n\\n2. Midterm #1, Midterm #2, Midterm #3 and corrections to any problems where points were deducted\\n3. Quizzes and corrections to any problems where points were deducted\\n\\n4. Any other handouts provided\\n\\nQUESTION: I am not in high school anymore. Why are you making us do a binder check? ®\\n\\nANSWER: Aside from mathematics, I hope to help you with your organizational skills for college. You\\nshould be maintaining all of your work as if they were valuable documents. That way, if there is a mistake on\\nmy part in inputting grade points, you can easily find and show me the error. Also, being organized with your\\nnotes will make studying for the exams an easier process.\\n\\nQUESTION: How do I earn credit for participation?\\n\\nANSWER: To earn the full 5% for participation, you must be present in class and provide me with your full\\nattention. This means you are following along with the lecture and filling in your notes, asking me any\\nquestions if something is unclear.\\n\\nQUESTION: What is my current grade in the class?\\nANSWER: I use Canvas to keep track of the scores you earn on each assignment, quiz, and exam. You\\nshould monitor it regularly to see your current standing in the course.\\n\\nGot a question that isn’t listed? Please email me at lienamanda@thda.edu.\\n\\x0cStudent Learning Outcome(s):\\n\\n* Analyze and synthesize the concepts of limits, continuity, and differentiation from a graphical, numerical,\\nanalytical and verbal approach, using correct notation and mathematical precision.\\n\\n*Evaluate the behavior of graphs in the context of limits, continuity and differentiability.\\n\\n*Recognize, diagnose, and decide on the appropriate method for solving applied real world problems in\\noptimization, related rates and numerical approximation.\\n\\x0c', metadata={'source': '/Users/eshaan/Desktop/projects/Tailor-Ed/data/test.json', 'seq_num': 2}),\n",
            " Document(page_content=\"SYLLABUS FOR MATH 1a, CALCULUS |: WINTER 2019\\nMath-001a-07, CRN: 34996\\n\\nInstructor: Dr. Wyatt Howard\\n\\nEmail: howardwyatt@fhda.edu\\n\\nClass Hours: Monday-Friday from 10:30A.M.-11:20A.M. in L61.\\n\\nOffice Hours: Mondays from 4:00P.M.-5:00P.M. and Tuesdays-Thursdays from\\n12:00P.M.-1:00P.M. in S76g.\\n\\nTextbook: Calculus, Early Transcendentals, 8th Ed. by James Stewart. We will plan on\\ncovering Chapters 2-4 .\\n\\nGrading:\\n\\nHomework: Homework will be assigned after almost every class and it will primarily\\ncome from the textbook (there is no online homework for this class). | will not collect\\n\\nall of your homework and grade each assignment. However, on exam days you need to\\nbring all of your homework with you to class. | will collect one assignment on exam\\ndays. Before you take the exam, | will pick one of these assignments at random and\\nyou will turn it in when you are finished with your exam. | will not accept late homework.\\nMake sure your homework is stapled, has the assignment number on the front page,\\nand exercise numbers listed on the front page or else points will be deducted. If you turn\\nin the wrong homework assignment, then you will receive a zero for that assignment. It\\nis your responsibility to make sure that you are organized and turn in the correct\\nhomework assignment. The homework will be graded on a scale of 1-10 where 10 isa\\nperfect score. | will be primarily grading the homework on effort and to give you\\nfeedback.\\n\\nBoard Quizzes: There will be 4 quizzes in this class. | do not allow make up quizzes.\\n\\nIn the calendar below, | have included the tentative dates of the quizzes. The quizzes\\nwill be done on the board in groups of at most three people. During the first and second\\nweek of class, | will discuss the details of how these board quizzes will be conducted.\\nThere will also be a quiz at the end of the first week of class testing your knowledge of\\nMath 41 and Math 42 concepts that will not be a board quiz.\\n\\nTests: There will be a total of 4 exams in the class: 3 midterms and 1 final. | do not give\\nmake up exams, with the possible exception of the final exam under extreme\\ncircumstances. In the event that you miss an exam, you will be permitted to replace the\\nzero you received on one midterm exam by your next midterm (or final exam in the\\nevent you miss the third midterm) grade on a percentage equivalent basis. You can use\\na scientific calculator\\n\\nfor the exams. You are not allowed to use a graphing calculator. The final exam will be\\ncumulative.\\n\\x0cTentative Dates for Midterms: Midterm 1: Monday, January 28th, Midterm 2:\\nWednesday, February 20th, Midterm 3: Monday, March 11th.\\n\\nFinal Exam: The date of the final is exam is on Thursday, March 28th from 9:15A.M.-\\n11:15A.M. The date of the final exam is set in stone and will not be changed.\\n\\nClass Participation and Academic Etiquette: You will be given 10 points for\\nparticipation and academic etiquette for this course. These 10 points make up 3% of\\nyour overall grade. Students will lose half a point for a tardy (late by 5 or more minutes\\nafter class begins) or for leaving 5 or more minutes before class is excused. If you have\\na valid excuse for why you are unable to arrive on time to class or need to leave early,\\nthen you need to email me and state the reason for why you were late or left early. | will\\ndecide if your reason is considered excused or not. Cell phones, computers, and any\\nother electronic devices are not allowed during class. If you are using one of these\\ndevices during class, then you will lose one point for each time that | see you using\\nthese devices. Disruptive behavior will not be tolerated, as well. If you are being\\ndisruptive and talking to another student during class, then you will lose a point for each\\nincident.\\n\\nAttendance: You are expected to be in class every day. If you have more than 10\\nrecorded absences, you may be dropped from the course. However, it is your\\nresponsibility\\n\\nto drop yourself in the event that you want to drop the class.\\n\\nClass Participation and Academic Etiquette 3%\\nQuizzes 10%\\n\\nMidterm 1 17%\\n\\nMidterm 2 20%\\n\\nMidterm 3 20%\\n\\nFinal 30%\\n\\nGrade Breakdown:\\n90- 100% = A-, A, At.\\n80-89% = B-, B, Bt.\\n70-79% = C.\\n\\n60-69% = D.\\n\\nbelow 60% = F.\\n\\nThis grading scale is not set entirely in stone. | may curve the class at the very end of\\nthe course, and letter grades will be determined by a curve at the instructor's discretion.\\nIt depends on how the entire class performs, but the above scale will be a good\\nindication of how you are doing in the course.\\n\\nCourse Description: Fundamentals of Differential Calculus.\\n\\nPrerequisites: Completion of Math 43 with a grade of C, or equivalent; qualifying score\\non Placement Test within the past calendar year.\\n\\x0cAttendance: You are expected to be in class every day. If you have more than 6\\nrecorded absences, you may be dropped from the course. However, it is your\\nresponsibility to drop yourself in the event that you want to drop the class.\\n\\nWarm-Up Exercises: Warm-up exercises will be given a few days a week. This will\\nconsist of 1-3 exercises that | will post on the board and have you work on either by\\nyourself or in groups when you enter class. After the first few minutes | will walk around\\nthe class to observe how everyone Is tackling the exercises and to provide help. These\\nproblems are intended to help warm-up your mind for the lecture that day. Please take\\nthem seriously.\\n\\nBlue Books: Each student is required to purchase 3 small blue books and 1 large blue\\nbook and turn them in to me during the first two weeks of class. | will talk more about\\nthis on the first day of class.\\n\\nFree Tutoring: The Math Tutoring Center in Room S43 offers free tutoring on Mondays-\\nThursdays from 9 : OOA.M.-5 : 30P.M. | strongly encourage you to utilize this resource.\\nMore information can be found here:\\n\\nhttp://www.deanza.edu/studentsuccess/mstrc/\\n\\nDisability Support Services: If you need to contact the Disability Support Services,\\nthen please contact them as soon as possible. More information can be found here:\\n\\nhttps://www.deanza.edu/dss/\\n\\nAcademic Integrity: This is pretty straightforward: Do not cheat on quizzes, exams,\\n\\nor directly copy other student's work. It is not worth getting caught and suffering the\\nconsequences. For more information about De Anza College's policy on academic\\n\\nintegrity:\\n\\nhttps://www.deanza.edu/studenthandbook/academic-integrity.html\\n\\nPolicies for This Class: These policies are part of the syllabus and will be strictly\\nenforced. By enrolling in this course, you as the student agree to accept these policies\\nand follow them and agree that the instructor reserves the right to drop a student from\\nthe course with a W if any of the policies are violated. Further action may also be\\ntaken against a student who violates specific policies, such as the policy on cheating.\\n\\nCell phone use (talking on your phone, texting, etc.) during lecture is not allowed. This\\nis considered to be rude behavior and tells me that you are not paying attention in class.\\nIf you are using your phone, then you will be warned once to stop. If it happens again,\\nthen you may be asked to leave the class and you will not be allowed back into the\\nclass until you emailed the instructor or talked to him before the next class meeting.\\n\\nlf you have an emergency and need to use your cell phone, then you are free to excuse\\nyourself from class to deal with the situation.\\n\\x0cTalking during class is also not allowed. This is also considered to be rude behavior,\\nand it is distracting to the professor. If you are being disruptive and talking to another\\nstudent during class, then | reserve the right to move you to the front of the classroom\\nor | may ask you to leave the class and you will not be allowed back until the class until\\nyou have emailed the instructor.\\n\\nTests must be completed by the time class time ends. You will receive a two minute\\nwarning before your time is fully up. When time is over, you must put down your writing\\nutensil and stop writing immediately. If you do not stop writing immediately, your test\\nmay not be collected and you may receive a grade of zero. Also, during exams\\neverything must be off of your desk and either in your backpack (or under your seat if\\nyou do not have a backpack). If the instructor sees any phones, paper, notebooks,\\ntextbooks, etc. out during an exam, then it will be considered cheating and the student\\nwill receive a zero for that exam. If the instructor observes a student placing his or her\\nhands beneath his or her desk for an extended period of time, the instructor may ask\\nthat student to stand up or move to another desk. If a student is observed with a cell\\nphone in his or her hands, lap, or other easily accessible place after the student has\\nreceived his or her test, that student will be considered cheating and will receive a zero\\non that test.\\n\\nlf a student is caught cheating, the instructor reserves the right to assign a grade of F\\nfor that exam/quiz or to drop the student with a W from the course. If a student is\\nreturned a graded test or quiz and the student changes his or her incorrect answers in\\norder to receive more points, the student is considered cheating and such an act will\\ncarry the same consequences as those mentioned above. If you are caught cheating on\\nthe final exam, you might receive a grade of F for the course.\\n\\x0cStudent Learning Outcome(s):\\n\\n* Analyze and synthesize the concepts of limits, continuity, and differentiation from a graphical,\\nnumerical, analytical and verbal approach, using correct notation and mathematical precision.\\n*Evaluate the behavior of graphs in the context of limits, continuity and differentiability.\\n*Recognize, diagnose, and decide on the appropriate method for solving applied real world\\nproblems in optimization, related rates and numerical approximation.\\n\\x0c\", metadata={'source': '/Users/eshaan/Desktop/projects/Tailor-Ed/data/test.json', 'seq_num': 3})]\n"
          ]
        }
      ],
      "source": [
        "pprint(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLGX4qzo49ae",
        "outputId": "aa22dbbe-df31-44d1-87f3-5a99f648209e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "9798"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(data[2].page_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "# loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
        "# data = loader.load()\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
        "all_splits = text_splitter.split_documents(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(all_splits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_community.embeddings import GPT4AllEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "\n",
        "vectorstore = Chroma.from_documents(documents=all_splits, embedding=GPT4AllEmbeddings())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "question = \"Each community\\nquiz will be scored out of 20 points. The lowest quiz score will be dropped.\"\n",
        "docs = vectorstore.similarity_search(question)\n",
        "len(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(page_content='you may work with anyone and everyone in the class to complete your quiz. Each community\\nquiz will be scored out of 20 points. The lowest quiz score will be dropped. There will be no', metadata={'seq_num': 1, 'source': '/Users/eshaan/Desktop/projects/Tailor-Ed/data/test.json'}),\n",
              " Document(page_content='you may work with anyone and everyone in the class to complete your quiz. Each community\\nquiz will be scored out of 20 points. The lowest quiz score will be dropped. There will be no', metadata={'seq_num': 1, 'source': '/Users/eshaan/Desktop/projects/Tailor-Ed/data/test.json'}),\n",
              " Document(page_content='you may work with anyone and everyone in the class to complete your quiz. Each community\\nquiz will be scored out of 20 points. The lowest quiz score will be dropped. There will be no', metadata={'seq_num': 1, 'source': '/Users/eshaan/Desktop/projects/Tailor-Ed/data/test.json'}),\n",
              " Document(page_content='Three exams will be given with no make-ups. The lowest exam will count for 10% while the\\nother two will count for 15% each. If an exam is missed under extreme circumstances and for a\\nvery valid reason, an equivalent of the final score will replace the missing exam score. If such\\nextreme circumstances occur it is the students responsibility to inform me immediately and\\n\\nprovide documentation of the circumstances.\\n\\nQuizzes', metadata={'seq_num': 1, 'source': '/Users/eshaan/Desktop/projects/Tailor-Ed/data/test.json'})]"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_community.llms import LlamaCpp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "objc[13769]: Class GGMLMetalClass is implemented in both /Users/eshaan/Desktop/projects/Tailor-Ed/venv/lib/python3.12/site-packages/gpt4all/llmodel_DO_NOT_MODIFY/build/libllamamodel-mainline-metal.dylib (0x10ac54260) and /Users/eshaan/Desktop/projects/Tailor-Ed/venv/lib/python3.12/site-packages/llama_cpp/libllama.dylib (0x14c6e4250). One of the two will be used. Which one is undefined.\n",
            "llama_model_loader: loaded meta data with 19 key-value pairs and 291 tensors from /Users/eshaan/Desktop/AI/models/llama-2-7b.Q4_K_M.gguf (version GGUF V2)\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
            "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
            "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 11008\n",
            "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 32\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  10:                          general.file_type u32              = 15\n",
            "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n",
            "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type q4_K:  193 tensors\n",
            "llama_model_loader: - type q6_K:   33 tensors\n",
            "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
            "llm_load_print_meta: format           = GGUF V2\n",
            "llm_load_print_meta: arch             = llama\n",
            "llm_load_print_meta: vocab type       = SPM\n",
            "llm_load_print_meta: n_vocab          = 32000\n",
            "llm_load_print_meta: n_merges         = 0\n",
            "llm_load_print_meta: n_ctx_train      = 4096\n",
            "llm_load_print_meta: n_embd           = 4096\n",
            "llm_load_print_meta: n_head           = 32\n",
            "llm_load_print_meta: n_head_kv        = 32\n",
            "llm_load_print_meta: n_layer          = 32\n",
            "llm_load_print_meta: n_rot            = 128\n",
            "llm_load_print_meta: n_embd_head_k    = 128\n",
            "llm_load_print_meta: n_embd_head_v    = 128\n",
            "llm_load_print_meta: n_gqa            = 1\n",
            "llm_load_print_meta: n_embd_k_gqa     = 4096\n",
            "llm_load_print_meta: n_embd_v_gqa     = 4096\n",
            "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
            "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 11008\n",
            "llm_load_print_meta: n_expert         = 0\n",
            "llm_load_print_meta: n_expert_used    = 0\n",
            "llm_load_print_meta: causal attn      = 1\n",
            "llm_load_print_meta: pooling type     = 0\n",
            "llm_load_print_meta: rope type        = 0\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 10000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_yarn_orig_ctx  = 4096\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: ssm_d_conv       = 0\n",
            "llm_load_print_meta: ssm_d_inner      = 0\n",
            "llm_load_print_meta: ssm_d_state      = 0\n",
            "llm_load_print_meta: ssm_dt_rank      = 0\n",
            "llm_load_print_meta: model type       = 7B\n",
            "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
            "llm_load_print_meta: model params     = 6.74 B\n",
            "llm_load_print_meta: model size       = 3.80 GiB (4.84 BPW) \n",
            "llm_load_print_meta: general.name     = LLaMA v2\n",
            "llm_load_print_meta: BOS token        = 1 '<s>'\n",
            "llm_load_print_meta: EOS token        = 2 '</s>'\n",
            "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
            "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
            "llm_load_tensors: ggml ctx size =    0.22 MiB\n",
            "ggml_backend_metal_buffer_from_ptr: allocated buffer, size =   123.81 MiB, (  183.02 / 10922.67)\n",
            "llm_load_tensors: offloading 1 repeating layers to GPU\n",
            "llm_load_tensors: offloaded 1/33 layers to GPU\n",
            "llm_load_tensors:        CPU buffer size =  3891.24 MiB\n",
            "llm_load_tensors:      Metal buffer size =   123.81 MiB\n",
            "..................................................................................................\n",
            "llama_new_context_with_model: n_ctx      = 2048\n",
            "llama_new_context_with_model: n_batch    = 512\n",
            "llama_new_context_with_model: n_ubatch   = 512\n",
            "llama_new_context_with_model: freq_base  = 10000.0\n",
            "llama_new_context_with_model: freq_scale = 1\n",
            "ggml_metal_init: allocating\n",
            "ggml_metal_init: found device: Apple M1 Pro\n",
            "ggml_metal_init: picking default device: Apple M1 Pro\n",
            "ggml_metal_init: using embedded metal library\n",
            "ggml_metal_init: GPU name:   Apple M1 Pro\n",
            "ggml_metal_init: GPU family: MTLGPUFamilyApple7  (1007)\n",
            "ggml_metal_init: GPU family: MTLGPUFamilyCommon3 (3003)\n",
            "ggml_metal_init: GPU family: MTLGPUFamilyMetal3  (5001)\n",
            "ggml_metal_init: simdgroup reduction support   = true\n",
            "ggml_metal_init: simdgroup matrix mul. support = true\n",
            "ggml_metal_init: hasUnifiedMemory              = true\n",
            "ggml_metal_init: recommendedMaxWorkingSetSize  = 11453.25 MB\n",
            "llama_kv_cache_init:        CPU KV buffer size =   992.00 MiB\n",
            "ggml_backend_metal_buffer_type_alloc_buffer: allocated buffer, size =    32.00 MiB, (  215.27 / 10922.67)\n",
            "llama_kv_cache_init:      Metal KV buffer size =    32.00 MiB\n",
            "llama_new_context_with_model: KV self size  = 1024.00 MiB, K (f16):  512.00 MiB, V (f16):  512.00 MiB\n",
            "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
            "ggml_backend_metal_buffer_type_alloc_buffer: allocated buffer, size =   164.02 MiB, (  379.28 / 10922.67)\n",
            "llama_new_context_with_model:      Metal compute buffer size =   164.00 MiB\n",
            "llama_new_context_with_model:        CPU compute buffer size =   164.01 MiB\n",
            "llama_new_context_with_model: graph nodes  = 1030\n",
            "llama_new_context_with_model: graph splits = 3\n",
            "AVX = 0 | AVX_VNNI = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | SSSE3 = 0 | VSX = 0 | MATMUL_INT8 = 0 | \n",
            "Model metadata: {'general.quantization_version': '2', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'tokenizer.ggml.bos_token_id': '1', 'tokenizer.ggml.model': 'llama', 'llama.attention.head_count_kv': '32', 'llama.context_length': '4096', 'llama.attention.head_count': '32', 'llama.rope.dimension_count': '128', 'general.file_type': '15', 'llama.feed_forward_length': '11008', 'llama.embedding_length': '4096', 'llama.block_count': '32', 'general.architecture': 'llama', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'general.name': 'LLaMA v2'}\n",
            "Using fallback chat format: None\n"
          ]
        }
      ],
      "source": [
        "n_gpu_layers = 1  # Metal set to 1 is enough.\n",
        "n_batch = 512  # Should be between 1 and n_ctx, consider the amount of RAM of your Apple Silicon Chip.\n",
        "\n",
        "# Make sure the model path is correct for your system!\n",
        "llm = LlamaCpp(\n",
        "    model_path=\"/Users/eshaan/Desktop/AI/models/llama-2-7b.Q4_K_M.gguf\",\n",
        "    n_gpu_layers=n_gpu_layers,\n",
        "    n_batch=n_batch,\n",
        "    n_ctx=2048,\n",
        "    f16_kv=True,  # MUST set to True, otherwise you will run into problem after a couple of calls\n",
        "    verbose=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    6405.46 ms\n",
            "llama_print_timings:      sample time =      28.83 ms /   256 runs   (    0.11 ms per token,  8880.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1491.28 ms /    24 tokens (   62.14 ms per token,    16.09 tokens per second)\n",
            "llama_print_timings:        eval time =   18137.84 ms /   255 runs   (   71.13 ms per token,    14.06 tokens per second)\n",
            "llama_print_timings:       total time =   20253.33 ms /   279 tokens\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'\\n округун: TERM 1 (1/6-3/25)\\nIn the early twentieth century, mathematicians had made significant progress in understanding the mathematics of geometry. They were able to use the results obtained from previous studies to solve problems that could not be solved by traditional methods. These solutions were called \"non-Euclidean\" and led to the creation of new mathematical theories such as analytic geometry and projective geometry, which were later applied in other fields like physics and engineering.\\nIn addition to these applications, non-Euclidean geometries also provided valuable insights into how people think about their world. By understanding how we perceive space around us through our own eyes (or other senses), it became possible for mathematicians to develop mathematical models that could accurately describe what we see in nature without making any assumptions about its physical properties like density or mass..\\nIn this course, you will learn about non-Euclidean geometry and how it has been used to solve problems in mathematics, engineering, physics, and other fields. You will also explore how people use their senses (or other ways of perceiving the world) in order to understand what they see around them; this is called \"perception.\" Finally,'"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm.invoke(\"MATH 1A SECTION 1 CRN 31484 WINTER 2019\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Build Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import PromptTemplate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        }
      ],
      "source": [
        "# Prompt\n",
        "prompt = PromptTemplate.from_template(\n",
        "    \"Summarize the main themes in these retrieved docs: {docs}\"\n",
        ")\n",
        "\n",
        "\n",
        "# Chain\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "\n",
        "chain = {\"docs\": format_docs} | prompt | llm | StrOutputParser()\n",
        "\n",
        "# Run\n",
        "question = \"Whom can we work with toin the class to complete the quiz?\"\n",
        "docs = vectorstore.similarity_search(question)\n",
        "chain.invoke(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HV7Z5u-4XlOo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U1E3AlbZXlRM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U3c1ENDaXlUV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxQwlD1aXmIs"
      },
      "source": [
        "# Locally running LLMs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "toUMBTMrXpdw",
        "outputId": "0a833036-d739-4761-afbc-df45eb62ce40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# %pip install --upgrade --quiet  langchain langchain-community langchainhub gpt4all chromadb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XPGBnfpZXpy8"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
        "data = loader.load()\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
        "all_splits = text_splitter.split_documents(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ij_xBUMoX7J0",
        "outputId": "b2f06c21-3c36-41cd-a589-2bde822384be"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: 100%|██████████| 45.9M/45.9M [00:00<00:00, 73.6MiB/s]\n",
            "Verifying: 100%|██████████| 45.9M/45.9M [00:00<00:00, 463MiB/s]\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.embeddings import GPT4AllEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "\n",
        "vectorstore = Chroma.from_documents(documents=all_splits, embedding=GPT4AllEmbeddings())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3k9BglHXX9jJ",
        "outputId": "204a2fb9-776e-4571-929d-7f66a76d177d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "question = \"What are the approaches to Task Decomposition?\"\n",
        "docs = vectorstore.similarity_search(question)\n",
        "len(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcdbsazQYWNr",
        "outputId": "53e070ef-9c87-4109-fa5c-3ef2fd76eeaf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(page_content='Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.', metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"})"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5liW5E2asxc",
        "outputId": "8d42b581-1174-4ca6-cc40-dd36e4d897cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.4/37.4 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# %pip install --upgrade --quiet  llama-cpp-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4Y2luukbo_l"
      },
      "outputs": [],
      "source": [
        "from langchain_community.llms import LlamaCpp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "vKXtpuE8atU3",
        "outputId": "5cc4f3ac-10a2-4fcd-be23-fbaa9dde068e"
      },
      "outputs": [
        {
          "ename": "ValidationError",
          "evalue": "1 validation error for LlamaCpp\n__root__\n  Could not load Llama model from path: /Users/rlm/Desktop/Code/llama.cpp/models/llama-2-13b-chat.ggufv3.q4_0.bin. Received error Model path does not exist: /Users/rlm/Desktop/Code/llama.cpp/models/llama-2-13b-chat.ggufv3.q4_0.bin (type=value_error)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-d108d9602d00>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Make sure the model path is correct for your system!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m llm = LlamaCpp(\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/Users/rlm/Desktop/Code/llama.cpp/models/llama-2-13b-chat.ggufv3.q4_0.bin\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mn_gpu_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_gpu_layers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/load/serializable.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lc_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pydantic/v1/main.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfields_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__pydantic_self__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidation_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalidation_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mobject_setattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__pydantic_self__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__dict__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValidationError\u001b[0m: 1 validation error for LlamaCpp\n__root__\n  Could not load Llama model from path: /Users/rlm/Desktop/Code/llama.cpp/models/llama-2-13b-chat.ggufv3.q4_0.bin. Received error Model path does not exist: /Users/rlm/Desktop/Code/llama.cpp/models/llama-2-13b-chat.ggufv3.q4_0.bin (type=value_error)"
          ]
        }
      ],
      "source": [
        "n_gpu_layers = 0  # Metal set to 1 is enough.\n",
        "n_batch = 512  # Should be between 1 and n_ctx, consider the amount of RAM of your Apple Silicon Chip.\n",
        "\n",
        "# Make sure the model path is correct for your system!\n",
        "llm = LlamaCpp(\n",
        "    model_path=\"/Users/rlm/Desktop/Code/llama.cpp/models/llama-2-13b-chat.ggufv3.q4_0.bin\",\n",
        "    n_gpu_layers=n_gpu_layers,\n",
        "    n_batch=n_batch,\n",
        "    n_ctx=2048,\n",
        "    f16_kv=True,  # MUST set to True, otherwise you will run into problem after a couple of calls\n",
        "    verbose=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WXvTtiUhb5hp"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
